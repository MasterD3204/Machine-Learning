{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import os"
      ],
      "metadata": {
        "id": "dLioik9EI7lr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = \"https://ai.stanford.edu/~amaas/data/sentiment/\"\n",
        "filename = \"aclImdb_v1.tar.gz\"\n",
        "filepath = tf.keras.utils.get_file(filename, root + filename, extract=True,\n",
        "                                   cache_dir=\".\")\n",
        "if \"_extracted\" in filepath:\n",
        "    path = Path(filepath) / \"aclImdb\"\n",
        "else:\n",
        "    path = Path(filepath).with_name(\"aclImdb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqqqzHXv-XdJ",
        "outputId": "e37e44a6-d42c-457c-d0a8-accc7cb5973b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "\u001b[1m84125825/84125825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_tree(path: Path, prefix: str = \"\", max_entries: int = 5):\n",
        "    \"\"\"In ra cấu trúc thư mục dạng cây từ một Path, giới hạn số mục con.\"\"\"\n",
        "    if not path.is_dir():\n",
        "        print(f\"{prefix}{path.name} [Not a directory]\")\n",
        "        return\n",
        "\n",
        "    entries = sorted(path.iterdir(), key=lambda p: (not p.is_dir(), p.name.lower()))\n",
        "    total = len(entries)\n",
        "    display_entries = entries[:max_entries]\n",
        "\n",
        "    for i, entry in enumerate(display_entries):\n",
        "        connector = \"── \" if i == len(display_entries) - 1 else \"── \"\n",
        "        print(f\"{prefix}{connector}{entry.name}\")\n",
        "\n",
        "        if entry.is_dir():\n",
        "            extension = \"    \" if i == len(display_entries) - 1 else \"|  \"\n",
        "            print_tree(entry, prefix + extension, max_entries=max_entries)\n",
        "\n",
        "    if total > max_entries:\n",
        "        print(f\"{prefix}── ... ({total - max_entries} more items)\")\n"
      ],
      "metadata": {
        "id": "9cDEDMIhubHI"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_tree(Path(\"/content/datasets/aclImdb_v1_extracted/aclImdb\"))"
      ],
      "metadata": {
        "id": "VSGAYhA2uwgP",
        "outputId": "0b795800-cc33-44cc-babe-f4f6be4f972c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "── test\n",
            "|  ── neg\n",
            "|  |  ── 0_2.txt\n",
            "|  |  ── 10000_4.txt\n",
            "|  |  ── 10001_1.txt\n",
            "|  |  ── 10002_3.txt\n",
            "|  |  ── 10003_3.txt\n",
            "|  |  ── ... (12495 more items)\n",
            "|  ── pos\n",
            "|  |  ── 0_10.txt\n",
            "|  |  ── 10000_7.txt\n",
            "|  |  ── 10001_9.txt\n",
            "|  |  ── 10002_8.txt\n",
            "|  |  ── 10003_8.txt\n",
            "|  |  ── ... (12495 more items)\n",
            "|  ── labeledBow.feat\n",
            "|  ── urls_neg.txt\n",
            "|  ── urls_pos.txt\n",
            "── train\n",
            "|  ── neg\n",
            "|  |  ── 0_3.txt\n",
            "|  |  ── 10000_4.txt\n",
            "|  |  ── 10001_4.txt\n",
            "|  |  ── 10002_1.txt\n",
            "|  |  ── 10003_1.txt\n",
            "|  |  ── ... (12495 more items)\n",
            "|  ── pos\n",
            "|  |  ── 0_9.txt\n",
            "|  |  ── 10000_8.txt\n",
            "|  |  ── 10001_10.txt\n",
            "|  |  ── 10002_7.txt\n",
            "|  |  ── 10003_8.txt\n",
            "|  |  ── ... (12495 more items)\n",
            "|  ── unsup\n",
            "|  |  ── 0_0.txt\n",
            "|  |  ── 10000_0.txt\n",
            "|  |  ── 10001_0.txt\n",
            "|  |  ── 10002_0.txt\n",
            "|  |  ── 10003_0.txt\n",
            "|  |  ── ... (49995 more items)\n",
            "|  ── labeledBow.feat\n",
            "|  ── unsupBow.feat\n",
            "|  ── ... (3 more items)\n",
            "── imdb.vocab\n",
            "── imdbEr.txt\n",
            "── README\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load tất cả data vào bộ nhớ"
      ],
      "metadata": {
        "id": "d_PeTLE1xqAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path(\"/content/datasets/aclImdb_v1_extracted/aclImdb\")"
      ],
      "metadata": {
        "id": "grta4TgSy1nV"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def review_path(folder_path):\n",
        "  return [path for path in folder_path.glob(\"*.txt\")]"
      ],
      "metadata": {
        "id": "tS_xVZWHxozY"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos = review_path(path/\"train\"/\"pos\")"
      ],
      "metadata": {
        "id": "9p1tQNcVyrg2"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in list(train_pos)[:5]:\n",
        "    print(p)"
      ],
      "metadata": {
        "id": "pCfV51l7zqSE",
        "outputId": "73c24964-ea17-4b02-fd29-180514698f44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets/aclImdb_v1_extracted/aclImdb/train/pos/10614_7.txt\n",
            "/content/datasets/aclImdb_v1_extracted/aclImdb/train/pos/6068_9.txt\n",
            "/content/datasets/aclImdb_v1_extracted/aclImdb/train/pos/696_10.txt\n",
            "/content/datasets/aclImdb_v1_extracted/aclImdb/train/pos/2791_10.txt\n",
            "/content/datasets/aclImdb_v1_extracted/aclImdb/train/pos/3887_10.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_neg = review_path(path/\"train\"/\"neg\")\n",
        "test_pos = review_path(path/\"test\"/\"pos\")\n",
        "test_neg = review_path(path/\"test\"/\"neg\")"
      ],
      "metadata": {
        "id": "FtPzZA6_zvKS"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_pos), len(train_neg), len(test_pos), len(test_neg)"
      ],
      "metadata": {
        "id": "6XJ6wHFl0Tvx",
        "outputId": "d707f598-bf0b-4b9c-d184-ced858bc320e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12500, 12500, 12500, 12500)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pos = test_pos[:5000]\n",
        "test_neg = test_neg[:5000]\n",
        "valid_pos = test_pos[5000:]\n",
        "valid_neg = test_neg[5000:]"
      ],
      "metadata": {
        "id": "unIhBe110ghj"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data(filepaths_pos, filepaths_neg):\n",
        "  reviews = []\n",
        "  labels = []\n",
        "  for filepaths, label in ((filepaths_pos,1), (filepaths_neg,0)):\n",
        "    for filepath in filepaths:\n",
        "      text = filepath.read_text()\n",
        "      reviews.append(text)\n",
        "      labels.append(label)\n",
        "  return tf.data.Dataset.from_tensor_slices((tf.constant(reviews), tf.constant(labels)))"
      ],
      "metadata": {
        "id": "EJCtolbJ1TLg"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = create_data(train_pos,train_neg)\n",
        "validation_data = create_data(valid_pos, valid_neg)\n",
        "test_data = create_data(test_pos, test_neg)"
      ],
      "metadata": {
        "id": "FoANlPJ-3Hz7"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load lần lượt từng batch data"
      ],
      "metadata": {
        "id": "vdL5M6ms8Smq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imdb_dataset(filepath_pos, filepath_neg):\n",
        "  dataset_pos = tf.data.TextLineDataset(filepath_pos,num_parallel_reads = tf.data.AUTOTUNE)\n",
        "  dataset_pos = dataset_pos.map(lambda review : (review, 1))\n",
        "\n",
        "  dataset_neg = tf.data.TextLineDataset(filepath_neg,num_parallel_reads = tf.data.AUTOTUNE)\n",
        "  dataset_neg = dataset_neg.map(lambda review : (review, 0))\n",
        "\n",
        "  return tf.data.Dataset.concatenate(dataset_pos, dataset_neg)"
      ],
      "metadata": {
        "id": "ETS9me119R8r"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_set = imdb_dataset(train_pos, train_neg).shuffle(25000, seed=42)\n",
        "train_set = train_set.batch(batch_size).prefetch(1)\n",
        "valid_set = imdb_dataset(valid_pos, valid_neg).batch(batch_size).prefetch(1)\n",
        "test_set = imdb_dataset(test_pos, test_neg).batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "WJ_hWT1J_Cqd"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxtoken = 10000\n",
        "vectorize = tf.keras.layers.TextVectorization(max_tokens=maxtoken ,output_mode = 'tf-idf' )\n",
        "review = train_set.map(lambda review, label: review)\n",
        "vectorize.adapt(review)"
      ],
      "metadata": {
        "id": "kiQhao1ADqR0"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize.get_vocabulary()[:20]"
      ],
      "metadata": {
        "id": "4FEsYMmzJRme",
        "outputId": "84ce0406-747e-48dd-e1ff-da77203a3c1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[UNK]',\n",
              " np.str_('the'),\n",
              " np.str_('and'),\n",
              " np.str_('a'),\n",
              " np.str_('of'),\n",
              " np.str_('to'),\n",
              " np.str_('is'),\n",
              " np.str_('in'),\n",
              " np.str_('it'),\n",
              " np.str_('i'),\n",
              " np.str_('this'),\n",
              " np.str_('that'),\n",
              " np.str_('br'),\n",
              " np.str_('was'),\n",
              " np.str_('as'),\n",
              " np.str_('for'),\n",
              " np.str_('with'),\n",
              " np.str_('movie'),\n",
              " np.str_('but'),\n",
              " np.str_('film')]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    vectorize,\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "])\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_set, epochs=10, validation_data=valid_set)"
      ],
      "metadata": {
        "id": "mc2WV-kIJfFZ",
        "outputId": "9a3c55c6-8f0e-463f-e937-c26af027a091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "    781/Unknown \u001b[1m27s\u001b[0m 28ms/step - accuracy: 0.8221 - loss: 0.4014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8222 - loss: 0.4012\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 30ms/step - accuracy: 0.9552 - loss: 0.1190\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 32ms/step - accuracy: 0.9844 - loss: 0.0468\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 30ms/step - accuracy: 0.9947 - loss: 0.0207\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 28ms/step - accuracy: 0.9953 - loss: 0.0175\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0072\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 28ms/step - accuracy: 0.9974 - loss: 0.0115\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - accuracy: 0.9985 - loss: 0.0057\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - accuracy: 0.9984 - loss: 0.0062\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - accuracy: 0.9992 - loss: 0.0031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e1a8ca3dc50>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_set)"
      ],
      "metadata": {
        "id": "rQXs8hA2J_cD",
        "outputId": "f4a815ba-d7c9-4464-bd7a-05d363f6c9a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8130 - loss: 1.5903\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2667756080627441, 0.8481000065803528]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    }
  ]
}